
## RAG
<div align=center>
    <image src="imgs/rag_agentic_rag.webp" width=500>
</div>

### 一、什么是 RAG（Retrieval-Augmented Generation）？

>核心思路
- 把“检索（Retrieval）”和“大模型生成（Generation）”结合，让模型在回答前先去外部知识库里“查资料”，再基于查到的资料生成答案。

>标准流程
- 1）用户提问 → 2）检索向量库/文档 → 3）把相关片段连同问题一起喂给 LLM → 4）LLM 根据这些“上下文”生成回答

>关键点
- 模型参数内的“固有知识” + 外部文档的“最新/私有知识”
- 检索只负责找到可能相关的信息，不负责“写答案”；生成由 LLM 完成。

### 二、为什么要用 RAG？（而不是只用 LLM）

- **解决知识时效性**: 模型训练时间之后的最新政策、内部文档、业务数据，靠模型记不住，只能靠检索接入
- **解决私有/垂直知识**: 企业知识库、代码库、专业文档（医疗、法律、金融）一般不在训练语料中，只能通过 RAG 注入给模型
- **降低幻觉（hallucination）**: 让模型“有据可依”，在检索到的材料范围内做总结/推理，而不是凭空编造。
- 可控性更好: 答案更多依赖可审计的文档，适合合规场景；更新知识只需要更新索引，不用重新训练大模型。
- 成本与工程灵活性: RAG 用一个通用 LLM + 向量库/检索，就能覆盖多个场景，扩展和维护比频繁微调模型便宜。

### 三、为什么后来要在 RAG 里加入 Agent？（RAG → Agentic RAG）

传统 RAG 大多是“一问一检一答”的单步流水线，在复杂任务、复杂系统里有明显局限，Agent 正好用来解决这些问题：

#### 1 任务复杂度提高，需要“多步推理 + 多轮检索”

>传统 RAG
- 一次检索 → 一次生成；不会自发分解任务，也不会自己决定“再查一次”“换种问法查”

>加上 Agent 后
- Agent 可以把一个大任务拆成多个子问题：
    - 先检索 A 再检索 B，或先总结再继续追问
    - 遇到信息不够时，主动“反思 + 重新提问 + 再检索”，形成闭环

#### 2 需要调用多种工具，RAG 只是其中一个

- 现实应用中，LLM 不只是“查知识库”: 还要查数据库、调接口、跑代码、调用搜索、写入系统等。

- Agent 作为“控制中枢”：
    - 视 RAG 为一个工具（retrieval tool）
    - 根据当前目标和上下文，在“RAG、SQL、搜索、函数调用……”之间选择、组合调用顺序。
- 典型模式：ReAct / Toolformer / function calling + RAG，共同组成 “会思考 + 会查资料 + 会操作系统” 的 Agent。

#### 3 需要更强的 `规划（Planning）与策略（Policy）` 能力

- 单纯 RAG：几乎没有显式规划逻辑，只是固定的检索-生成流程。
- Agent 增强后：
    - 可以有显式的“计划 + 执行 + 反思”结构：先规划要查哪些类型信息 → 决定使用哪种检索策略 → 逐步完成任务。
    - 可以根据环境反馈（工具返回结果、API 报错、用户追问）调整下一步动作

#### 4 多 Agent 协作，更易实现复杂工作流

- 复杂系统中常常需要：知识检索 Agent、数据分析 Agent、执行 Agent、审计 Agent 等分工合作。
- RAG 只是其中一个“知识检索专家”，由上层协调 Agent 调度。
- 这样比“一个 RAG pipeline 承担所有逻辑”更清晰、可扩展、可维护。

#### 5 提升鲁棒性与可观测性

- Agent 引入显式的“状态”和“过程”：它做了哪些步骤、用了什么工具、哪些检索有用/无用，都可以记录下来，便于监控和调试。
- 可以加入“监督 Agent”或“评审 Agent”对检索结果和最终回答进行质量检查，进一步降低幻觉和错误。

### 简要类比
- 只有 LLM：像一个“博学但记忆过时、又爱胡编”的顾问
- 加 RAG：给这个顾问配了一个“高效资料室”，他会先查资料再回答
- 再加 Agent：给顾问配了“项目经理”+“工具箱”：能拆任务、选工具、反复查资料、写报告、调用系统，把“查资料 + 决策 + 执行”串成一个完整的闭环