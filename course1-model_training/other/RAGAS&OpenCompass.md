## RAGAS & OpenCompass
一句话定位（先给结论）

| 工具              | 最适合用在                       | 不适合用在                         |
| --------------- | --------------------------- | ----------------------------- |
| **RAGAS**       | **RAG 系统质量评估**（检索 + 生成是否有效） | 通用能力回归、Function Call、Text2SQL |
| **OpenCompass** | **模型能力基准评测 & 微调/量化回归对比**    | 在线 RAG 端到端质量、业务定制指标           |


👉 一句话：

- RAGAS = RAG 专项体检工具
- OpenCompass = 模型能力 & 回归对比工具

### 一、RAGAS：用在什么地方最合适
#### 1️⃣ RAG 场景的“端到端质量评估”（最核心）

你可以用 RAGAS 来回答这些问题：

- 检索出来的文档 到底有没有用
- 模型回答 是否真的基于检索内容
- 回答 是否覆盖了问题关键信息
- 有没有“看似合理但不基于文档的胡编”

RAGAS 核心指标（你应该怎么理解）

| 指标                     | 实际在评什么    | 业务含义          |
| ---------------------- | --------- | ------------- |
| Faithfulness           | 回答是否基于上下文 | 是否“有证据的回答”    |
| Answer Relevancy       | 回答是否回答了问题 | 有没有跑题         |
| Context Precision      | 检索是否“少而准” | 噪声文档多不多       |
| Context Recall         | 检索是否“没漏”  | 关键文档有没有捞到     |
| Answer Correctness（可选） | 对不对       | 需要 GT 或 Judge |


👉 非常适合你用在：

- 对比 不同检索策略（BM25 vs Dense vs Hybrid）
- 对比 不同 chunk 策略
- 对比 不同 SFT / LoRA 模型在 RAG 下的表现
- 验证 量化后 RAG 是否更容易幻觉

#### 2️⃣ 用 RAGAS 看 SFT / LoRA / 量化 对 RAG 的影响

你之前问的这些问题，RAGAS 能直接回答一部分：

| 你的问题                | RAGAS 能否覆盖 | 怎么用                      |
| ------------------- | ---------- | ------------------------ |
| SFT 后通用能力是否下降       | ❌          | 用 OpenCompass            |
| Function call 有没有提升 | ❌          | 专项评测                     |
| LoRA 掉点没有           | ✅（RAG 场景）  | 对比 Faithfulness / Recall |
| INT4/INT8 掉点没有      | ✅（RAG 场景）  | 看 hallucination 是否上升     |
| 是否按格式输出             | ❌          | schema 校验                |


>关键点
- 👉 RAGAS 是 “RAG 条件下的模型表现”，不是“模型本体能力”。

#### 3️⃣ RAGAS 最容易踩的坑（很重要）

##### ❌ 不要用 RAGAS 评：

- 意图识别 / 槽位抽取
- Text2SQL / Function call
- 通用推理、数学、代码

##### ❌ 不要把 RAGAS 分数当“模型强弱”

它高度依赖：
- 检索质量
- prompt
- chunk 策略
- 上下文长度

#### ✅ 正确姿势

- 固定检索和 prompt
- 只对比“模型版本 / 量化方案”
- 看趋势，不迷信绝对分数

### 二、OpenCompass：用在什么地方最合适
#### 1️⃣ 微调 / LoRA / 量化 的“回归测试工具”（核心用途）

OpenCompass 非常适合你解决这些问题：

| 你的问题             | OpenCompass 是否适合 | 原因           |
| ---------------- | ---------------- | ------------ |
| SFT 后通用能力是否下降    | ✅                | 标准 benchmark |
| LoRA 微调后是否掉点     | ✅                | 同一评测集对比      |
| INT4 / INT8 是否掉点 | ✅                | 可重复、可量化      |
| 不同训练策略横向对比       | ✅                | 支持多模型并跑      |



常用 benchmark（举例）

| 能力   | 数据集          |
| ---- | ------------ |
| 通用理解 | MMLU / CMMLU |
| 中文   | C-Eval       |
| 推理   | BBH / GSM8K  |
| 代码   | HumanEval    |
| 对话   | MT-Bench（可选） |


#### 2️⃣ OpenCompass 在你评测体系里的“位置”

结合你之前的 8 个问题，可以这样放：
```
                 ┌────────────┐
                 │ OpenCompass│
                 │ 通用/回归  │
                 └─────┬──────┘
                       │
     ┌─────────────────┼─────────────────┐
     │                 │                 │
专项任务评测     RAGAS（RAG）     人工 / 自研脚本
(Function/SQL)   检索+生成质量      (格式/槽位)
```

👉 OpenCompass = 底座能力 + 回归安全网

#### 3️⃣ OpenCompass 不适合直接做的事

##### ❌ 不适合：

- RAG 端到端评测（它不懂检索）
- 业务意图/槽位（schema 不一样）
- Function call（没工具环境）
- 严格 JSON schema 输出

##### ✅ 正确做法：
用它回答一个问题：“这个模型版本整体有没有退化？”

### 三、RAGAS vs OpenCompass：直接对照表（重点）
| 维度             | RAGAS               | OpenCompass    |
| -------------- | ------------------- | -------------- |
| 核心对象           | RAG 系统              | 模型本体           |
| 是否需要检索         | 必须                  | 不需要            |
| 是否业务相关         | 强                   | 弱              |
| 是否适合回归测试       | 部分                  | 非常适合           |
| 是否支持 LoRA/量化对比 | RAG 场景下             | 全面             |
| 输出指标           | Faithfulness/Recall | Accuracy/Score |
| 是否能发现“幻觉”      | 非常强                 | 较弱             |



### 四、推荐你的“组合使用姿势”（最实用）
标准落地组合（强烈推荐）

>1️⃣ OpenCompass

- 每次：SFT / LoRA / 量化后必跑
- 目标：确认“底座没坏”

>2️⃣ 专项评测（自研）

- Function call / Slot / Text2SQL
- 目标：确认“核心业务涨了”

>3️⃣ RAGAS

- RAG 相关改动必跑
- 目标：确认“不是靠胡编在答”

>4️⃣ 人工抽检

- 兜底 + 校准自动指标

#### 一句经验总结
- OpenCompass 解决“模型是不是退化了”
- RAGAS 解决“RAG 是不是在胡说”
- 业务指标解决“你到底赚没赚到钱”