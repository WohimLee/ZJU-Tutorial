## 例子

### 🟦 1️⃣ BLEU（机器翻译常用）——中文例子

#### 📝 设定

**参考答案：**

> 他今天去了北京

**模型输出：**

> 他今天去北京

可以看到：
👉 少了一个“了”



#### ▶ 第一步：看 1-gram（按词）

参考词序列：
他 / 今天 / 去 / 了 / 北京

模型词序列：
他 / 今天 / 去 / 北京

匹配词 = 4 个（除了“了”）

模型总词数 = 4

```
1-gram precision = 4 / 4 = 1.0
```


#### ▶ 第二步：看 2-gram

参考 2-gram：

| 词序列  |
| ---- |
| 他 今天 |
| 今天 去 |
| 去 了  |
| 了 北京 |

模型 2-gram：

| 词序列  |
| ---- |
| 他 今天 |
| 今天 去 |
| 去 北京 |

匹配 = 2（前两个）

模型总 2-gram 数 = 3

```
2-gram precision = 2 / 3 ≈ 0.67
```


#### ▶ 第三步：算 BLEU（简化理解）

```
BLEU = 几何平均 × 简短惩罚
≈ sqrt(1.0 × 0.67)
≈ 0.82
```

因为长度比较接近，所以惩罚≈1



#### ⭐ 直观解释

> 输出几乎与参考一样
> → BLEU 得分高



#### ❌ 语义一样但说法不同，BLEU 就可能低

例如：

参考：

> 他今天去了北京

模型：

> 他今天到北京了

意思几乎一样
但很多 n-gram 不一致
→ BLEU 下降
👉 说明 BLEU **偏重字面相似**

---

### 🔴 2️⃣ ROUGE（摘要常用）——中文例子

假设我们在做「新闻摘要」

#### 📝 参考摘要

> 北京今天出现大范围降雨

#### 📝 模型摘要

> 北京今天下雨了



#### ▶ 计算 ROUGE-1（按词匹配）

参考词：
北京 / 今天 / 出现 / 大范围 / 降雨

模型词：
北京 / 今天 / 下雨 / 了

匹配词：
北京 / 今天 /（降雨≈下雨 不算匹配）

👉 也可能评测中做词切分后能部分算上，但我们先按严格字面理解

匹配 = 2
参考总词数 = 5

```
Recall = 2 / 5 = 0.4
```

#### ⭐ 怎么理解？

> ROUGE = 我有没有覆盖参考摘要中的关键信息？

模型至少提到了：
✔ 北京
✔ 今天
❌ 大范围
❌ 降雨（字面不同）

所以：
👉 覆盖度一般
👉 ROUGE 不算高



#### 🔍 和 BLEU 的区别

| 指标    | 更看重什么     |
| ----- | --------- |
| BLEU  | 输出像不像参考   |
| ROUGE | 有没有覆盖参考内容 |

适合：

* **机器翻译 → BLEU**
* **摘要 → ROUGE**



### 🟡 3️⃣ 困惑度 PPL——中文例子

假设模型在句子：

> 我 今天 吃 饭

上预测到：

| 词  | 概率   |
| -- | ---- |
| 我  | 0.5  |
| 今天 | 0.25 |
| 吃  | 0.15 |
| 饭  | 0.10 |

（这里简单假设）


#### ▶ 困惑度直观理解

👉 模型越确定
👉 概率越集中
👉 困惑度越低

大致可以理解为：

```
PPL = 模型平均像在从多少个候选词中挑一个
```

所以
如果模型很笃定某个词

```
PPL ≈ 小 → 好
```

---

#### ❌ 反例：毫无意义却低困惑度

如果模型非常确定：

> 哈 哈 哈 哈 哈 哈 哈

每次预测“哈”的概率 = 0.99

👉 困惑度会非常低
👉 但显然不是好文本

这说明：

> 困惑度只看概率，不看内容质量



### 🧭 放到真实任务里理解

| 场景     | 中文例子  | 推荐指标   | 原因         |
| ------ | ----- | ------ | ---------- |
| 翻译     | 英→中对照 | BLEU   | 看字面一致      |
| 摘要     | 新闻压缩  | ROUGE  | 看覆盖信息      |
| 语言模型训练 | 预测下个字 | PPL    | 看模型是否懂语料模式 |
| 评估可读性  | 小说生成  | 人工+多指标 | 自动指标有限     |



### 📌 一句话总结（中文版）

* **BLEU：**
  👉 *我翻译得像不像原答案？*
* **ROUGE：**
  👉 *我有没有抓住答案里的重点？*
* **PPL：**
  👉 *我预测下一个字有多自信？*
