
## 训练 & 测试数据
关键在于：**不要用同一份“原始 output 文本”同时当训练目标和评测标准**——否则 OpenCompass 很难客观打分，而且会被“写作风格/模板”影响。

我建议把每条样本拆成两条“衍生资产”：

* **训练样本（给 LLaMA-Factory）**：保留现在的 output，但要做“规范化”（强结构、禁越权）
* **评测样本（给 OpenCompass）**：把 output 解析/抽取成结构化标签（罪名/法条/刑期区间），评测用这些“硬标签”，而不是比对整段文字


### 1) 对当前数据先做 3 个清洗（必须）

#### A. 合并 reference

现在 reference 是数组，训练/评测都建议合并成单字符串，方便 prompt 和解析：

* `ref_text = "\n".join(reference)`

#### B. 统一 input 前缀

input 有时带“请预测… / 三段论…”，有时没有。训练时最好统一成固定模板：

* 训练模板里把“任务要求”放在 instruction，不要依赖 input 内部的随机提示语

#### C. 标记“高风险样本”（只用于评测或降权）

从给的例子看，至少要把这几类标出来：

* **竞合/多罪名**（如 judgement_predit-8：同时乱判“组织/强迫/引诱/容留/介绍…”，明显不稳）
* **情节严重判断**（judgement_predit-6 里把“打鸟玩耍”推到“情节严重”很可疑）
* **错误或过度推断**（judgement_predit-10 把条文的“聚众/公共场所/恶劣情节”等推断得很随意）

这些样本如果直接 SFT，会把模型带偏。



### 2) 给 LLaMA-Factory：把每条转成“可控的训练格式”

#### 目标：训练输出**结构固定**、**不越权**、**引用不编造**

我建议用 **Alpaca 格式**（instruction/input/output）：

**instruction（固定不变）**：

* 明确：法律助理角色
* 明确：只能依据给定法条（open-book）
* 明确：不得给具体刑期（年/月）
* 明确：必须输出 JSON（或固定四段）

**input（每条变化）**：

* 案件事实 + 给定法条

**output（每条变化）**：

* 现有 output 需要“重写/规范化”为结构化输出（建议用规则/LLM 进行一次批处理规范化）

#### 推荐训练输出格式（强烈建议 JSON）

比如：

```json
{
  "applicable_law": ["刑法第114条"],
  "crime": "以危险方法危害公共安全罪",
  "key_facts": ["拉拽档杆/司机致车辆失控", "造成财产损失", "未造成严重后果"],
  "reasoning": "行为足以危害公共安全，且符合条文规定的危险方法；未造成严重后果。",
  "sentence_range": "三年以上十年以下有期徒刑",
  "uncertainty": "最终量刑需结合具体情节裁量"
}
```

> 训练阶段强结构的好处：**模型学到“答题格式”**，后面评测也能用规则直接抽字段。

#### 对“明显有问题的 output”怎么处理？

像 judgement_predit-8 这种输出明显混乱（多罪名乱判），建议：

* **不进训练集**（只进评测集 / 或直接剔除）
* 或者降权（如果有 sample weight 机制）



### 3) 给 OpenCompass：把每条样本转成“结构化 reference + 可比对评测”

#### 核心：OpenCompass 的评测不要拿整段 `output` 做 reference

而是做：

* `crime`（罪名）
* `law_articles`（条号）
* `sentence_range`（法定刑区间）

#### 现在数据里这些字段怎么来？

优先级建议：

1. **从 reference 里抽条号 + 刑期区间**（正则/规则最稳）
2. **从 output 里抽罪名**（如“构成X罪/犯X罪”）
3. 抽不到就用 LLM API 做结构化抽取补齐（只对少量失败样本）

OpenCompass 的数据项示例（JSONL）：

```json
{
  "id": "judgement_predit-1",
  "question": "【案件事实】...（input）...",
  "reference": {
    "law_articles": ["刑法第114条"],
    "crime": "以危险方法危害公共安全罪",
    "sentence_range": "三年以上十年以下有期徒刑"
  },
  "meta": {
    "open_book": true,
    "ref_text": "《刑法》第一百一十四条：..."
  }
}
```

然后可以做两套评测：

* **Open-book**：把 `ref_text` 拼到 question 里（更贴合训练方式）
* **Closed-book**：不提供 ref_text（测泛化和法条召回）

### OpenCompass evaluator（至少先做 3 个硬指标）

* Crime hit（罪名命中：pred 是否包含 crime）
* Law hit（pred 是否提到条号/条文）
* Range hit（pred 是否包含区间）

软指标（建议后加）：

* 是否越权给具体刑期（检测 “年/月/判处X年X个月”）
* 是否编造法条（pred 出现 reference 不包含的条号）



### 4) 切分策略：怎么把 16k 分成 train / dev / test

这类数据随机切分会“虚高”，建议至少做到：

#### 最低标准：按罪名/条号分层切分

保证 Train/Dev/Test 的罪名和条号分布相似。

#### 更好：按案情相似度分组切分（防同案改写泄漏）

对 `input` 做 embedding 聚类/近邻成簇，然后：

* 同一簇只进一个 split


### 5) 给的例子里，我会怎么标“训练 vs 只评测”

基于展示的 1–10：

* **适合训练（前提：output 规范化成结构化 JSON）**：1、2、3、4、5、7、9
* **更适合只评测/或至少不直接训练**：6、8、10
  原因很直接：
* 6：把“情节严重”推断得很随意，容易教坏模型
* 8：罪名与条文对应混乱（还引入条文不存在的概念组合），极易污染
* 10：把条文条件（公共场所/聚众/恶劣情节）推断得过度，风险高

> 全量 16k 里也会有类似“推断过度/幻觉/模板化”样本，这些要么剔除，要么只放评测集做压力测试。



### 6) 能不能一套数据两用？

可以一套数据两用，但要做到**两条流水线**：

#### 流水线 A（训练）

`raw -> 清洗 -> 规范化输出(JSON) -> 导出 Alpaca -> LLaMA-Factory`

#### 流水线 B（评测）

`raw -> 抽取标签(crime/law/range) -> 导出 OpenCompass -> 规则评测(+可选Judge)`

**千万别**：训练用原 output，评测也用原 output 做“文本相似度/ROUGE”。那样法律任务会被写作风格支配，结论不可信。

