## LLaMA-Factory
- https://llamafactory.readthedocs.io/zh-cn/latest/
### 一、LLaMA-Factory 是什么？（一句话定位）

LLaMA-Factory 是一个：面向 LLM 微调与对齐的“工程化整合框架 / 工厂化流水线”

它的目标不是发明新算法，而是：
- 把 主流 LLM 微调技术 全部封装好
- 让你 几乎不用写代码
- 直接完成 SFT / DPO / PPO / LoRA / QLoRA / DeepSpeed 等流程

📌 本质定位：“上层训练平台 / 统一训练入口”

### 二、LLaMA-Factory 解决的核心问题
传统 Hugging Face 训练的问题
- 库太多（transformers / peft / trl / deepspeed）
- 配置复杂
- 工程重复
- 新手上手成本高

LLaMA-Factory 的思路：把主流训练范式标准化成一套 CLI / WebUI

### 三、LLaMA-Factory 支持的能力一览
>1️⃣ 模型支持
- LLaMA / LLaMA-2 / LLaMA-3、Qwen / Qwen2、Baichuan、Mistral / Mixtral、InternLM 等
- 📌 底层仍然是 transformers

>2️⃣ 训练范式（非常全面）
- 👉 几乎覆盖当前主流 对齐路线

    | 范式             | 是否支持   | 底层实现          |
    | -------------- | ------ | ------------- |
    | 预训练            | ⚠️（有限） | transformers  |
    | **SFT**        | ✅      | Trainer / TRL |
    | **DPO**        | ✅      | TRL           |
    | **PPO / RLHF** | ✅      | TRL           |
    | ORPO / KTO     | ✅      | TRL           |
    | RM 训练          | ✅      | transformers  |




>3️⃣ 微调方式
- 全参数微调、LoRA、QLoRA、AdaLoRA
- 👉 底层使用 PEFT

>4️⃣ 训练加速 / 分布式
- DeepSpeed（ZeRO-1 / 2 / 3）、Accelerate、FSDP（部分支持）

>5️⃣ 推理与评测
- 模型合并（merge LoRA）、批量推理、简单评测、Chat 模式测试


### 四、LLaMA-Factory 的内部结构
```
┌───────────────────────────┐
│        LLaMA-Factory       │
│                           │
│  CLI / WebUI / Config     │  ← 用户入口
│            ↓              │
│   Training Pipeline       │  ← 统一流程
│            ↓              │
│ transformers / peft / trl │  ← 实际干活
│            ↓              │
│ accelerate / deepspeed    │  ← 跑得动
└───────────────────────────┘

                     ┌────────────────┐
                     │  LLaMA-Factory │
                     │ (训练平台层)   │
                     └───────┬────────┘
                             │
        ┌──────────────┬─────┼──────┬─────────────┐
        │              │     │      │             │
 transformers        peft   trl  accelerate   deepspeed
 (模型)         (高效微调) (对齐)   (启动)    (分布式)

```

📌 它 不是替代这些库，而是 把它们“打包”


