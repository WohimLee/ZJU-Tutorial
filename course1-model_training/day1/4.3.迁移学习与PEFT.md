## 迁移学习与参数高效微调（PEFT）

>本节目标：

- 理解为什么微调大模型需要 PEFT
- 掌握常用的 PEFT 技术：Prompt-Tuning、P-Tuning、Prefix-Tuning、Adapter、LoRA、QLoRA
- 理解它们之间的差异与应用场景

### 📌 一、迁移学习（Transfer Learning）

迁移学习思想：

- 用“已经训练好的能力”解决新任务
- 不必从头训练整个模型

在大模型中体现为：**预训练模型（Frozen） + 小任务微调模块（Trainable）**

这正是 PEFT 的核心理念。

### 📌 二、为什么需要 PEFT？

随着 LLaMA、Qwen 等模型规模持续扩大（7B → 70B → 100B+），
全参数微调（Full fine-tuning）变得极其昂贵和困难。

#### 1️⃣ 显存限制（Memory Constraints）

问题：

- 微调 7B 模型通常需要 40GB 显存
- 70B 模型则需要 300GB+ 显存
- 普通公司/个人无法承担

PEFT 的解决方式：
👉 只训练极少量新增参数（0.1%～3%）
👉 不修改原模型参数（冻结大部分权重）
→ 显存需求降低 10～50 倍

#### 2️⃣ 训练成本（Cost Efficiency）

全参数微调需要：
- 巨量梯度更新
- 分布式训练
- 大规模数据与时间

PEFT 则让训练：

- 可以在单机/消费级 GPU 上运行
- 成本从“百万级”降为“几百到几千人民币”
- 更适合快速迭代业务需求

#### 3️⃣ 工程效率（Engineering Flexibility）

业务通常需要多个版本的微调模型：
- 法律问答模型
- 医疗客服模型
- 金融文档分析模型
- 多语言模型

如果每次都全参微调：
→ 需要存储多个 “几十 GB 的模型文件”
→ 管理、部署成本巨大

PEFT 的优势：
👉 每个任务只需保存几 MB～几百 MB 的“微调增量参数”
👉 通过“合并/加载 Adapter 权重”快速切换任务


### 📌 三、常见 PEFT 技术方法（重点）

下面讲解业界最主流的 4 种 PEFT 方法：

#### 1️⃣ LoRA（Low-Rank Adaptation）—— 最常用 / 默认首选
##### 原理：

- 不训练原权重 W
- 引入一个低秩分解：`W' = W + A·B`
- A、B 的尺寸很小，因此可训练参数量极少

##### 优点：

- 效果好、稳定
- 训练速度快
- 强任务泛化能力
- 适用于绝大多数 NLP 任务：分类、对话、生成等

##### 应用场景：

- 指令微调（Instruction Tuning）
- 智能客服对话
- 文案生成、内容优化
- 垂直行业知识增强

#### 2️⃣ QLoRA（Quantized LoRA）—— 极致节省显存的微调方式
##### 原理：

- 先把模型权重量化到 4-bit（NF4）
- 在量化模型上应用 LoRA
- 计算仍保持高精度（double quantization）

##### 优点：
- 可以在 单张 24GB 显卡 上微调 33B 模型
- 在极低显存下保留高效果
- 目前开源界应用非常广泛（LlamaFactory、Firefly、Ultrachat 等都使用）

##### 结论：

👉 如果显存有限，QLoRA 是最佳选择。

#### 3️⃣ Adapter / AdapterFusion——模块化微调
##### 原理：

- 在模型每层插入一个“小型前馈网络”，只训练 Adapter 层
- 原模型参数完全冻结

##### 优点：

- 模块化强，便于组合多个任务
- 每个任务只需几 MB 到几十 MB
- 对模型侵入性低

##### 缺点：
- 效果略逊于 LoRA（在部分任务上）

##### 适用场景：
- 一个模型服务多个任务
- 多语言、多领域需求

#### 4️⃣ Prefix Tuning / Prompt Tuning——最轻量级的方法
原理：

- 不改变模型结构
- 只训练“前缀向量”（prefix）
- 本质是在 Transformer 每层添加一个 trainable 的提示向量

优点：
- 参数量最小（可以少到 KB 级别）
- 适合超大模型（比如 70B、100B+）

缺点：

- 表达能力不如 LoRA/Adapters
- 适合简单任务，不适合复杂推理

应用场景：

- 文本分类
- 工业场景中“少参数快速适配”需求

### 📌 四、PEFT 方法对比总结
| 方法                | 参数量 | 显存需求 | 适用场景     | 效果   | 难度 |
| ----------------- | --- | ---- | -------- | ---- | -- |
| **LoRA**          | 小   | 低    | 最通用任务    | ⭐⭐⭐⭐ | 易  |
| **QLoRA**         | 更小  | 极低   | 显存紧张、模型大 | ⭐⭐⭐⭐ | 中  |
| **Adapter**       | 中等  | 低    | 多任务、多语言  | ⭐⭐⭐  | 中  |
| **Prefix Tuning** | 极小  | 极低   | 简单任务、大模型 | ⭐⭐   | 易  |

### 📌 五、本节小结（Summary）

- 大模型微调成本高 → 需要 PEFT
- PEFT 通过“只训练少量参数”实现：
    - 显存节省
    - 成本下降
    - 训练速度提升
    - 更灵活的工程部署
- 主流方法包括：LoRA、QLoRA、Adapter、Prefix Tuning
- 实际应用中：
👉 LoRA = 默认最佳选择
👉 QLoRA = 显存不足时的神器
👉 Adapter = 多任务灵活选择
👉 Prefix Tuning = 最轻量级方案