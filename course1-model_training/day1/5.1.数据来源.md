## 数据来源
### 一、微调训练的数据到底从哪来？
#### 1️⃣ 主流数据来源（按质量从低到高）
##### （0）自有线上日志
>👉 特点
- 真实的用户需求
- 真实的场景
##### （1）公开指令数据（冷启动）

- Alpaca / Dolly / ShareGPT / OpenAssistant
- Wiki + 模板生成（instruction → answer）
- 论坛、问答、GitHub issue、StackOverflow

>👉 特点

- 数量大
- 风格噪声多
- 常用于 SFT 第一阶段

##### （2）模型自生成（Self-Instruct / Bootstrapping）

- 用一个“还不错”的模型生成指令+回答
- 人类只做抽检 / 修正

>👉 特点

- 成本低、可扩展
- 容易产生风格坍缩（model bias）
- 必须做 去重、去模板化、风格多样化

##### （3）人工高质量标注（Alignment 核心）

- 专业标注员 / 领域专家
- 多轮对话、反思链、拒答样本

>👉 特点
- 成本极高
- 是“对齐能力”的决定性因素
- LIMA 正是强调这一层

##### （4）在线反馈数据（RLHF / DPO）

- 人类偏好排序
- A/B test
- 真实用户对话日志（强过滤）

>👉 特点

- 最接近真实分布
- 标签是偏好而不是“标准答案”

### 二、数据规模应该是怎么样的？（非常重要）
#### 1️⃣ 一个反直觉但正确的结论

**微调 ≠ 预训练**
微调阶段的数据规模是“能力激活器”，不是“能力来源”。

因此：

| 阶段        | 数据量            |
| --------- | -------------- |
| 预训练       | 1T+ tokens     |
| SFT       | **10k ～ 2M 条** |
| Alignment | **几千 ～ 十万级**   |

#### 2️⃣ 工程经验上的「有效区间」
通用聊天 / 助手模型（SFT）

| 模型规模 | 推荐 SFT 数据量  |
| ---- | ----------- |
| 7B   | 20k – 100k  |
| 8B   | 30k – 150k  |
| 14B  | 100k – 500k |
| 32B  | 300k – 1M   |


👉 超过这个区间，边际收益迅速下降

#### 3️⃣ 为什么不是“模型越大，数据越多越好”？

原因有三：
- 对齐数据本身分布极窄
- 大模型已经具备能力，只需要“激活”
- 噪声对大模型伤害更大（over-alignment）

这正是 LIMA 的核心论点之一。

### 三、LIMA（Less Is More for Alignment）到底说对了什么？
**LIMA 的核心结论（简化版）**

- 1k 高质量样本 > 100k 低质量样本

**论文实验：**
- 使用 1000 条人工精修指令
- 7B 模型在多项评测上接近甚至超过用 50k 指令训练的模型

**为什么成立？**

- 指令分布覆盖“认知模式”而不是“事实空间”
- Alignment 不是学习知识，而是学习：
    - 什么时候拒绝
    - 如何解释
    - 如何多步推理
- 高质量数据避免了：
    - 模板化
    - 表层模仿
    - 语言风格坍缩

### 四、标签平衡：一个被严重误解的问题
#### 1️⃣ 先说结论

大模型微调中，“类别平衡”不是首要目标，“行为覆盖”才是

#### 2️⃣ 什么情况下需要“平衡”？
##### （1）安全 / 拒答 / 敏感内容

- 必须 过采样
- 现实世界是长尾，但模型必须“非常会拒绝”
>例如：
- 暴力 / 自残 / 色情 / 非法行为
- 即使只占真实分布的 1%，训练中也可能占 10–30%

##### （2）工具调用 / 特殊格式输出
- JSON / function call / SQL
- 如果不强化，模型会“偶尔失忆”

#### 3️⃣ 哪些不需要刻意平衡？

- 闲聊 vs 推理
- 写作 vs 问答
- 知识类 vs 常识类

👉 模型预训练已经学过，微调只要“允许它用”

### 五、针对不同模型规模，如何定“有效数据量”？
>一个工程化经验公式（非理论）
- 有效 SFT 样本数 ≈ 2k × log₂(模型参数量 / 1B)

举例：

| 模型  | log₂ | 建议高质量样本 |
| --- | ---- | ------- |
| 7B  | ≈2.8 | ~6k     |
| 14B | ≈3.8 | ~8k     |
| 32B | ≈5   | ~10k    |


👉 这是 LIMA / OpenAI / Anthropic 内部实践非常接近的量级

其余数据更多是：
- 风格扩展
- 鲁棒性增强
- 特殊能力注入

### 六、长尾数据怎么考虑？（这是高手才会问的问题）
#### 1️⃣ 长尾不是“多”，而是“代表性”

##### 错误做法 ❌

把所有小众任务都加进来

##### 正确做法 ✅

抽象成“能力原型”

#### 2️⃣ 长尾处理的三种高级方法
##### （1）能力原型抽样

- 不是“写Rust宏”
- 而是“复杂约束下的代码生成”

👉 一个样本可覆盖一类任务

##### （2）困难样本挖掘（Hard Example Mining）

- 模型当前答错的
- 犹豫的
- 风格不一致的

这是 最有价值的长尾

##### （3）动态课程学习（Curriculum）

- 先学通用
- 再注入长尾
- 最后对齐安全

### 七、给你一个“真正可落地”的总结
如果你现在要训一个 7B/8B 模型：

推荐配置

- 5k–10k：人工高质量指令（LIMA 风格）
- 20k–50k：多样化 SFT（自生成 + 清洗）

重点过采样：
- 拒答
- 多轮对话
- 推理链

👉 不要追求 100k+，除非你能保证质量