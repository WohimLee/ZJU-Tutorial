## 通用能力数据
>一句话结论（先记住）
- 中文通用能力数据，80% 应该来自：👉 你自己构造 + 中文高质量指令数据

### 一、中文通用能力数据，分三类来准备（强烈推荐）
>A 类｜“保形训练数据”（会进 SFT / GRPO-KL）

- 目的：防遗忘、防风格漂移
- 占比：1%~5%
- 特点：回答“像原始 qwen3-8B”

>B 类｜通用回归集（只评估，不训练）

- 目的：刹车
- 规模：200~500 条就够
- 特点：稳定、可复现、覆盖关键中文能力

>C 类｜参考生成数据（base 自蒸馏）

- 目的：最稳的中文对齐
- 来源：原始 qwen3-8B 自己生成

### 二、最推荐的【中文公开数据源】（按实用度排序）
#### 1️⃣ 中文指令数据（首选）
>🔹 Belle / Belle-Open
- 用途：中文指令遵循、解释、问答
- 优点：
    - 中文原生
    - 指令形式自然
    - 适合 instruction-following 保形
- 用法：
    - 不要全量
    - 抽 几百到几千条高质量样本
    - 用于：
        - Base SFT 的 1%~3%
        - 通用回归集的一部分

>🔹 COIG（Chinese Open Instruction Generalist）
- 用途：多任务中文指令
- 覆盖：分类、改写、QA、推理
- 用法：
    - 按 task 抽样（每类几十条）
    - 非常适合做“能力覆盖型回归集”

>🔹 Firefly / Chinese-Alpaca（谨慎）

- 用途：基础中文 instruction
- ⚠️ 注意：风格较老、有模板化倾向
- 用法：
    - 少量使用
    - 只做保形，不做主训练

#### 2️⃣ 中文对话 / 写作（少量）
>🔹 ShareGPT 中文子集（严格过滤）

- 用途：多轮对话、自然表达
- ⚠️ 风险：噪声、越狱 / 不安全 prompt
- 用法：只留：正常聊天、无 system 攻击、短多轮（2~4 轮）

#### 3️⃣ 中文评测集（只用于回归，不训练）
>🔹 CMMLU（选子集）

- 常识
- 阅读理解
- 推理

👉 不要当训练数据，只当对照指标

### 三、最重要的一类：你“自己就能做”的中文通用数据

这是性价比最高、也是最稳的方案。

#### ✅ 方法：用 qwen3-8B 自己“定锚”
##### Step 1｜写 200~300 条中文 prompt

覆盖这些维度（非常关键）：

| 能力   | 示例           |
| ---- | ------------ |
| 指令遵循 | “请分三点说明……”   |
| 写作   | 邮件 / 通知 / 总结 |
| 中英混合 | 中→英 / 英→中    |
| 长文本  | 文章摘要         |
| 推理   | 中文逻辑/因果      |
| 格式   | JSON / 列表    |
| 拒答   | 明显不合理请求      |


##### Step 2｜用 原始 qwen3-8B 生成回答

- 不加任何 adapter
- 不做后处理
- 直接保存

##### Step 3｜用途

- 通用回归集（gold）
- 抽 50~150 条 → 做 保形 SFT 数据

👉 这是防通用能力下降最强的“保险丝”，没有之一。

### 四、中文 GRPO 阶段：通用数据怎么用（很关键）
#### ❌ 不要做的事

- 不要给中文通用任务设计 reward
- 不要用 LLM 打分中文通用能力（噪声极大）

#### ✅ 正确用法
##### 1️⃣ prompt 混入，但只用 KL

- 在 GRPO prompts 中混入 1%~5% 中文通用 prompt
- 不计算 reward
- 只通过 KL(reference=Base-SFT) 约束

##### 2️⃣ 中文回归集当“红线”
- 每 N step 跑一次
- 观察：
    - 回答是否变短/变啰嗦
    - 指令是否不听
    - 中文是否“机器味变重”

一旦明显下降：

- 提高 KL
- 降 LR
- 或停训

### 五、一个【可以直接照抄的中文通用数据配置】
>通用回归集（300 条）

- 100 条：你手写 prompt + qwen3-8B 输出
- 80 条：Belle / COIG 抽样
- 40 条：中英互译
- 40 条：中文写作
- 40 条：格式/JSON

>保形训练数据（SFT）

- 从回归集中抽 50~100 条
- Belle / COIG 中精选 100~300 条
- 总占比：1%~3%

### 六、常见中文场景踩坑（提前告诉你）

❌ 英文通用数据直接翻译成中文
❌ 用 CMMLU 之类 benchmark 直接混训
❌ 通用中文数据比例过高（>10%）
❌ 不做“base 定锚”，只信公开数据

### 最重要的一句话（帮你定策略）

在中文领域，最好的“通用能力数据”，
不是别人给你的，而是你用 base 模型亲手“钉死”的那一小撮样本。