## LoRA 与 QLoRA 的原理与应用场景

>本节目标

- 理解 LoRA 的低秩分解思想
- 理解 QLoRA 的 4bit 量化机制
- 掌握两者的对比与适用任务

#### 大模型微调场景
- 适合 LoRA: 回答风格调整、问答对记忆
- 不适合 LoRA, 需要全量微调: 领域知识灌注、代码/数学能力增强、function calling能力增强、agent 能力增强


### 📌 一、LoRA 的核心思想：低秩分解（Low-Rank Adaptation）

#### 1️⃣ 传统微调的问题

传统 Fine-tuning 需要更新模型所有权重（比如 7B 参数模型的 7B 个参数），
→ 显存巨大
→ 训练极慢
→ 多任务需要保存多个“整模型”

因此 LoRA 提出了一个高效替代方案：

#### 2️⃣ LoRA 的数学原理（低秩分解）

对 Transformer 中某个权重矩阵 W（d×k）：

LoRA 不直接训练 W，而是增加可训练矩阵：
$$
W^{\prime}=W+\Delta W
$$

其中：
$$
\Delta W=B A
$$

- A 为低秩矩阵（r × k）
- B 为低秩矩阵（d × r）
- r（秩）通常是 4、8、16，非常小 → 所以新增参数量远小于 W

低秩分解思想：
- 模型在新任务上的变化往往是“可压缩的”，
- 无需更新全部参数，只需更新一个低秩近似即可。

#### 3️⃣ LoRA 的实现方式（工程角度）

在注意力层中插入 LoRA 模块，例如 Q、K、V 映射层：**Linear → Linear + LoRA**

训练时：
- 原始权重 W 冻结
- 仅训练 A、B（LoRA 增量）
- 推理时：合并成 W' 或动态加和

4️⃣ LoRA 特点总结

优点：
- 显存占用低（减少 10～50 倍）
- 效果接近全参数微调
- 多任务可加载多个 LoRA Adapter
- 易于实现、主流微调方式

缺点：

- 对于极端复杂任务（如数学推理）可能略弱于全参
- 需要选择合适的秩 r（避免欠拟合/过拟合）

### 📌 二、QLoRA：基于 4-bit 量化的极致显存节省微调


QLoRA 是 LoRA 的升级，为了进一步降低显存需求。

#### 1️⃣ QLoRA 的核心思想

在冻结模型参数前，将其量化为 `4-bit（NF4）`再进行微调。

QLoRA = **4bit 量化 + LoRA + DoubleQuant 技术**

这样：

- 原模型加载显存 → 降低 75%
- 仍可保持高精度
- LoRA 参数继续使用 FP16/FP32 训练，不受量化影响

#### 2️⃣ QLoRA 的关键技术
##### （1）NF4（NormalFloat 4）量化

- 比传统 int4 更适合 LLM
- 分布更接近正态分布的张量
- 保持高精度语义信息

##### （2）Double Quantization（双量化）

- 对量化权重的缩放因子再次量化
- 进一步降低显存占用

##### （3）PEFT + LoRA
- 在 4bit 模型上插入 LoRA 模块
- LoRA 参数保持高精度训练 → 效果不损失

#### 3️⃣ QLoRA 的显存优势（关键卖点）
| 模型规模 | 全参微调显存 | LoRA 显存 | QLoRA 显存        |
| ---- | ------ | ------- | --------------- |
| 7B   | 40GB+  | 16GB    | **8–12GB**      |
| 13B  | 80GB+  | 30–40GB | **16GB**        |
| 33B  | 无法单卡   | 80GB    | **24GB（可单卡微调）** |

👉 利用 QLoRA，普通开发者可以用 消费级显卡 微调大模型。

#### 4️⃣ QLoRA 的优缺点

优点：

- 显存需求最低
- 支持超大模型（33B、70B）微调
- 效果接近甚至超过 FP16 LoRA
- 成本极低

缺点：

- 推理时若不合并权重，需要额外量化库支持
- 对硬件性能敏感（例如 BitsAndBytes）

### 📌 三、LoRA vs QLoRA：如何选择？

下面从 4 个维度进行对比：

#### 1️⃣ 显存需求

- QLoRA < LoRA << 全参
- 若显存 ≤ 24GB → QLoRA 是唯一现实选择

#### 2️⃣ 效果

- 大多数任务中：QLoRA ≈ LoRA
- 极少数场景（如复杂长序列任务）：LoRA 略胜

#### 3️⃣ 工程兼容性

- LoRA 更成熟，兼容性最佳
- QLoRA 依赖 bitsandbytes，部分环境可能需要额外配置

#### 4️⃣ 推理部署

- LoRA：需要合并或适配 LoRA 权重
- QLoRA：支持 4bit 推理，但需兼容运行环境

### 📌 四、典型适用场景总结
#### 🔸 LoRA 的典型场景
- 指令微调（Instruction Tuning）
- 对话优化（Chatbot）
- 文本生成、写作助手
- 任务型微调（如分类/Q&A）

适用于：⭐⭐⭐ 中小模型（7B–13B）微调、服务器显存足够

#### 🔸 QLoRA 的典型场景

- 超大模型（33B–70B+）微调
- 本地微调、个人设备微调
- 显存不足但对效果要求较高
- 企业私有数据微调（成本敏感）

适用于：⭐⭐⭐⭐⭐ 显存紧张/成本敏感/大模型微调

### 📌 五、本节小结（Summary）

- LoRA：低秩分解 → 少量可训练参数 → 高效微调
- QLoRA：4-bit 量化 + LoRA → 极低显存 → 单卡处理大模型
- LoRA 更稳定成熟，QLoRA 更节省显存与成本
- 选择建议：
    - GPU资源足够 → LoRA
    - 显存不足 / 模型大 → QLoRA