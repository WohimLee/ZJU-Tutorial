## 大模型微调流程

>本节目标
- 理解大模型从数据 → 训练 → 评估 → 部署的标准流程
- 掌握模型对齐（Alignment）及指令微调的作用

### 📌 一、LLM 全流程概览
#### 1）数据准备（Data Preparation）

大模型的训练效果高度依赖数据质量。
典型数据准备包括：

- 数据收集：网络爬虫、开源语料、企业私有数据
- 数据清洗：去噪、去重、文本规范化
- 数据标注：指令数据、对话数据、分类标签等
- 数据格式化：转换成模型可读格式（如 ChatML）

🔎 关键点：高质量数据比模型规模更重要！

#### 2）微调（Fine-tuning）

- 使用任务相关的、规模较小的标注数据
- 常见任务：问答、分类、摘要、对话
- 可以使用 PEFT / LoRA 等低成本方式进行
- 目标：使模型“适应特定任务或领域”



#### 3）模型评估（Evaluation）

评估方式因任务而异：

##### ● 自动评估指标

- 分类准确率、F1、AUC
- Rouge、BLEU（生成任务）
- MMLU、CMMLU（通用能力）
- Retrieval recall@k（检索任务）

##### ● 人类评估（Human Evaluation）

- 对话流畅度
- 事实正确性
- 安全性与价值偏好

##### ● 对齐任务的专用评估

- 审查是否“有害输出减少”
- 是否遵循指令
- 是否符合人类偏好

#### 4）模型部署（Deployment）

部署方式包括：
- 本地推理（CPU/GPU）
- 云服务（如 ModelArts、SageMaker、阿里 PAIE）
- 量化后部署（INT8/INT4/FP8）以节省显存
- 在线服务（API）或离线批处理（Batch）

关键问题：
- QPS（吞吐）
- 延迟（Latency）
- 显存与成本
- 安全与隐私

### 📌 二、预训练 vs 微调：为什么不能只靠预训练？

预训练的大模型往往：

- 语言能力强
- 泛化能力好
- 但缺乏任务意识（task awareness）
- 不知道“你希望它做什么”

因此需要：

- 指令微调（Instruction Tuning）
- 对齐（Alignment）
- 强化学习（RLHF）

使模型更像“助理”，而不是“语言生成器”。


### 📌 四、本节小结（Summary）
LLM 的完整流程是：数据 → 预训练/微调 → 对齐 → 评估 → 部署

