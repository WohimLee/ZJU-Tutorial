## 大模型的诞生

### 🧭 一、大模型系列是怎么“诞生”的？

一个成熟的 LLM 系列从无到有大致会经历以下阶段：

#### 1. 确定目标与体系结构（Architecture Design）

团队首先决定：

- 模型类型：Decoder-only (LLM)、Encoder-only（Reranker）、Encoder-Decoder（某些任务）
- 模型大小：比如 1.8B、7B、32B、72B 等
- 模型功能：是否支持多语言、多模态、代码能力、长上下文等
- 训练方式：全量训练？增量？蒸馏？

Qwen 系列基于类似 GPT 的 Transformer Decoder-only 架构，并在 attention、position encoding 等方面进行了优化（比如 rope 多尺度化、缓存优化等）。

### 🧪 二、训练 Base 模型：全系列的核心
#### Base 模型是什么？

Base（基础）模型是 未经指令微调的纯语言模型。
它的能力来源于大量无监督文本训练，如：

- 网页
- 书籍
- 代码
- 论文
- 社区讨论
- 多语言数据

Base 的训练步骤：
#### 1. 构建海量语料（Data Pipeline）

数据会经过：
- 去重
- 质量评估
- 脏词过滤
- 格式规范化
- 语言检测
- 专业语料扩张（法律、医学、数学、代码）

Qwen3 的训练据公开信息使用了大量中文与英文数据，并通过 mixture-of-quality 技术控制不同数据对最终模型的影响。

#### 2. 自监督训练（Pretraining）

目标函数通常是：让模型预测下一个 token（Next-token Prediction）

Base 模型在这个阶段“习得”：
- 语言理解
- 知识储备
- 推理能力
- 世界常识
- 代码结构感

这和 ChatGPT 的 GPT-3/3.5 Base 阶段类似。

结果就是产生了 Qwen3-0.6B、1.8B、7B、14B、32B 等 Base 模型。

### 🧩 三、指令微调（SFT）：让模型变“有用”

Base 模型只懂语言，不懂人类交互。
于是要进行 Supervised Fine-Tuning (SFT)。

>SFT 数据包括：
- 问答数据（QA）
- 多轮对话
- 代码任务
- 数学推理
- 工程推理
- 角色扮演
- 应用场景指令

模型通过SFT学习“按照人类需求回答问题”的方式，从而诞生：Qwen3-Chat 系列，例如：Qwen3-7B-Chat、Qwen3-72B-Chat。

### 🎚 四、偏好对齐（DPO / PPO / RLHF）

SFT 可以教模型“怎么回答”，但无法保证：
- 安全性
- 礼貌度
- 合理性
- 稳定性
- 不胡说

因此加入对齐训练，例如：
- RLHF：强化学习（PPO）方式让模型根据人类偏好改变行为
- DPO：近年来更流行，直接用偏好数据优化模型

此阶段会产生 对齐后的 Chat 模型（例如 Qwen3-Chat）。

### 🔎 五、Embedding 模型从哪里来？
Embedding 模型不是 Base 的简单裁剪，而是 **重新训练** 或 **迁移训练的 Encoder 模型**

>用途：
- 向量检索（RAG）
- 文本相似度
- 语义分类
- 搜索排序

大多数 embedding 模型使用 双向 Transformer Encoder（类似 BERT），而不是 Decoder-only。

Embedding 的来源：
- 从头训练一个 Encoder 模型
- 从 Base 模型蒸馏得到 Encoder
- 用对比学习（contrastive learning）训练

Qwen3 的 embedding 多采用：
- 对比学习
- 大规模文本对齐数据
- 多语言表示优化

### ⚖️ 六、Reranker 是如何产生的？

Reranker 通常是 Cross-Encoder，输入为 `query + candidate`，输出一个相关性分数。

它的训练方式：
- 使用大量标注好的 `(query, passage, relevance)` 数据
- 采用 `pairwise / listwise` ranking loss
- 也可能蒸馏一个大模型（如 Qwen3-72B）

作用：
- 检索排序
- 问答系统的重新排序（RAG 中使用）
- 做推理判断（例如判断哪段理由最合理）

Reranker 通常比 embedding 更“重”，但更准确。

Qwen3-Reranker 也是这样产生的。

### 👁 七、Vision（多模态）模型又是怎么来的？

Vision LLM（如 Qwen-VL）通常来自：

#### 1. 训练一个视觉编码器（ViT、EfficientViT 等）

输入图片 → 输出向量。

#### 2. 做多模态对齐（Projection）

把视觉特征投影到语言空间。

#### 3. 用混合数据训练：

- OCR 图片
- 图文配对
- 表格
- UI截图
- 数学图形
- 文档图像

最终集成到大模型形成：Qwen3-VL（视觉语言模型）

### 🧱 八、一个 LLM 系列如何“扩展成全家桶”？

以 Qwen3 为例：

| 模型类型                | 用途    | 训练方式                |
| ------------------- | ----- | ------------------- |
| Base                | 纯语言理解 | 大规模无监督训练            |
| Chat                | 对话、应用 | Base + SFT + 对齐     |
| Math/Code/Reasoning | 专项强化  | 领域数据再训练             |
| Embedding           | 语义向量  | Encoder + 对比学习      |
| Reranker            | 排序判断  | Cross-Encoder 排序训练  |
| VL                  | 图像理解  | Vision 编码器 + LLM 对齐 |
| Audio/Speech        | 音频理解  | 声学模型 + LLM          |


一个大模型生态最终形成 多模型协同工作 的产品族。

### 📦 九、为什么要有多个参数规模？

不同参数规模对应不同应用场景：
- 小模型（1-4B） → 本地端侧部署
- 中模型（7-14B） → 中等推理能力、平衡成本
- 大模型（30-70B） → 强推理、长上下文、高质量生成
- 超大模型（100B+） → 专注极致性能（如 Qwen3-max 级别）

### 🧠 十、把整个流程串起来（总图）

→ 1. 收集和清洗海量数据
→ 2. 训练 Base 模型
→ 3. 做 SFT 得到 Chat 模型
→ 4. 做 RLHF/DPO 对齐优化
→ 5. 训练额外的 Embedding / Reranker / Vision 模型
→ 6. 蒸馏、量化、压缩，形成不同参数规模
→ 7. 发布完整的模型家族（如 Qwen3 系列）